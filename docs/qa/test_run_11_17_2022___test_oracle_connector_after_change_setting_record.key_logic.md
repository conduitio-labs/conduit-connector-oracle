| ID       | Title                                                                                                                                                                                                                                                      | Status | Comment |
| -------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------ | ------- |
| T3160028 | The user can't create the Oracle source connector with empty the "orderingColumn" key -> the system returns an error \`"orderingColumn" config value must be set\`                                                                                         | Passed |         |
| T3160029 | The user can't create the Oracle source connector with special characters (example::,@±\* and other) in the "orderingColumn" key -> the system returns an error                                                                                            | Passed |         |
| T3160030 | The system validates the name of the column which using for ordering after starting the pipeline -> the error occurs if the name of the column which using for ordering is an invalid                                                                      | Passed |         |
| T3160031 | The user can create the Oracle source connector with a valid name of the column which using for ordering (the user can use any existing column from the table)                                                                                             | Passed |         |
| T3160032 | \--------------------- No required config -------------------                                                                                                                                                                                              | Passed |         |
| T3160033 | Check that the "keyColumns" key isn't necessary and the user can create the Oracle source connector without (or an empty) this key (By default: primary key of a table or value of the orderingColumn)                                                     | Passed |         |
| T3160034 | The user can't create the Oracle source connector with special characters (example::,@±\* and other) in the "keyColumns" key -> the system returns an error                                                                                                | Passed |         |
| T3160037 | The user can't create the Oracle source connector with the long name column (\`validate:"max=128") in the "keyColumns" key -> the system returns an error \`"keyColumns" config value is too long\`                                                        | Passed |         |
| T3160035 | The system validates the column name, that records should use for their Key, while transferring data -> the error occurs if the column name is invalid (not exist in the Oracle)                                                                           | Passed |         |
| T3160038 | 1\. The table in the Oracle has the next columns: ""ID"" (primary key); Name; City -> 2. Create the Oracle source connector with config "keyColumns":"Name"-> 3. Start the pipeline -> the pipeline is running; the "Name" column is used as "keyColumns"  | Passed |         |
| T3160039 | 1\. The primary key isn't used for the table in the Oracle -> 2. Create the Oracle source connector with "keyColumns" key (use any column) -> 3. Start the pipeline -> data is transferred                                                                 | Passed |         |
| T3160036 | The user can create the Oracle source connector with more than one valid column name in the "keyColumns" key ( The name of the column that records should use for their key fields.)                                                                       | Passed |         |
| T3160068 | The user can create the Oracle source connector with valid column names in the "keyColumns" key ( The name of the column that records should use for their key fields.)                                                                                    | Passed |         |
| T3160040 | Check that the Oracle source connector can't be created without the "keyColumn" key (or empty)-> the system returns an error \`"keyColumn" config value must be set\`                                                                                      | Passed |         |
| T3160041 | The system validates the column name, that records should use for their Key, while transferring data -> the error occurs if the column name is different in metadata Source and Oracle Destination (edge case)                                             | Passed |         |
| T3160042 | 1\. The table in the Oracle has the next columns: "ID" (primary key); Name; City -> 2. Create the Oracle destination connector with config "keyColumn":"Name"-> 3. Start the pipeline -> the pipeline is running; the "Name" column is used as "keyColumn" | Passed |         |
| T3160043 | 1\. The primary key isn't used for the table in the Oracle -> 2. Create the Oracle dest connector connector with "keyColumn" key (use any column) -> 3. Start the pipeline -> data is transferred                                                          | Passed |         |
| T3160044 | The user can create the Oracle destination connector with valid column names in the "keyColumn" key (<br>The name of the column that records should use for their key fields.)                                                                             | Passed |         |
| T3160045 | Data from two different Oracle source connectors are transferred to the File Destination connector                                                                                                                                                         | Passed |         |
| T3160046 | Data from two different Oracle source connectors are transferred to the Materialize Destination connector                                                                                                                                                  | Passed |         |
| T3160053 | Data from two different Oracle source connectors are transferred to the NATS PubSub Destination connector                                                                                                                                                  | Passed |         |
| T3160055 | Data from two different Oracle source connectors are transferred to the Vitess Destination connector                                                                                                                                                       | Passed |         |
| T3160047 | Try to transfer data from two Oracle Sources with the same config to the File Destination - > the "\\"CONDUIT_SNAPSHOT_\\" already exists" error is occurred                                                                                               | Passed |         |
| T3160048 | Try to transfer data from two Oracle Sources with the same config to the Materialize Destination - > the "\\"CONDUIT_SNAPSHOT_\\" already exists" error is occurred                                                                                        | Passed |         |
| T3160054 | Try to transfer data from two Oracle Sources with the same config to the NATS PubSub Destination - > the "\\"CONDUIT_SNAPSHOT_\\" already exists" error is occurred                                                                                        | Passed |         |
| T3160056 | Try to transfer data from two Oracle Sources with the same config to the Vitess Destination - > the "\\"CONDUIT_SNAPSHOT_\\" already exists" error is occurred                                                                                             | Passed |         |
| T3160049 | The new data that is added to the Oracle table is transferred to the Destination while the pipeline is running (or after restarting the pipeline )                                                                                                         | Passed |         |
| T3160050 | Remove data in Oracle table while running pipeline (or restart run pipeline) -> data is removed from Materialize table                                                                                                                                     | Passed |         |
| T3160057 | Remove data in Oracle table while running pipeline (or restart run pipeline) -> data is removed from Vitess table                                                                                                                                          | Passed |         |
| T3160051 | Update data in Oracle while running pipeline (or restart run pipeline) -> data is updated in Materialize table                                                                                                                                             | Passed |         |
| T3160058 | Update data in Oracle while running pipeline (or restart run pipeline) -> data is updated in Vitess table                                                                                                                                                  | Passed |         |
| T3160052 | 1\. "id" is the Primary Key in Oracle table-> 2. Use "name" as the Primary Kay when creating the Oracle source (isn't a Primary Key in table)-> 3. Create the Postgres (or Materializ) Dest-> 4. Start the pipeline-> doesn't affect; data is transferred  | Passed |         |
| T3160059 | Data from two different Snowflake source connectors are transferred to the Oracle Destination connector                                                                                                                                                    | Passed |         |
| T3160064 | Data from two different NATS PubSub source connectors are transferred to the Oracle Destination connector                                                                                                                                                  | Passed |         |
| T3160065 | Data from two different Vitess source connectors are transferred to the Oracle Destination connector                                                                                                                                                       | Passed |         |
| T3160060 | Transfer data from the Snowflake Sources to two Oracle Destination with the same config - > data is transferred and not duplicated in the Oracle table(data is transferred once and an error occurs if the primary key is used in the Oracle table)        | Passed |         |
| T3160061 | Transfer data from the NATS PubSub Sources to two Oracle Destination with the same config - > data is transferred and not duplicated in the Oracle table(data is transferred once and an error occurs if the primary key is used in the Oracle table)      | Passed |         |
| T3160066 | Transfer data from the Vitess Sources to two Oracle Destination with the same config - > data is transferred and not duplicated in the Oracle table(data is transferred once and an error occurs if the primary key is used in the Oracle table)           | Passed |         |
| T3160062 | Remove data in Stripe (or Snowflake) while running pipeline (or restart run pipeline) -> data is removed from the Oracle table                                                                                                                             | Passed |         |
| T3160063 | Update data in Stripe (or Snowflake) while running pipeline (or restart run pipeline) -> data is updated in the Oracle table                                                                                                                               | Passed |         |
| T3160067 | 1\. "id" is the primary key in Oracle table-> 2. Use "name" as the primary key when creating the Oracle dest (isn't a primary key in table)-> 3. Create the Snowflake Source -> 4. Start the pipeline-> doesn't affect; data is transferred                | Passed |         |
